# План по нормализации и очистке данных

**Цель:** Преобразовать "сырые" извлеченные данные в единый, чистый и готовый к анализу формат. Скрипт инкапсулирует всю логику в виде переиспользуемой функции для легкой интеграции в пайплайн.

---

### **Шаг 1: Структура и модульность**

-   **Скрипт:** `data_normalization/normalize_data.py`.
-   **Ключевая функция:** `normalize_data(data)` принимает список словарей и возвращает очищенный список. Это позволяет импортировать ее в другие модули.
-   **Автономный запуск:** При запуске напрямую скрипт читает данные из `input/final_json_1.json` и сохраняет результат в `output/normalized_data.json`, что удобно для тестирования.

---

### **Шаг 2: Нормализация значения (`value`)**

-   **Цель:** Преобразовать сложноформатированную строку `value` в единое числовое значение (`float`).
-   **Логика:**
    1.  **Очистка:** Удаляются текстовые приписки (`about`, `approx.`), операторы (`<`, `~`, `±`), пробелы.
    2.  **Диапазоны:** Для форматов `X-Y` или `X to Y` берется **верхнее значение** (Y).
    3.  **Научная нотация:** Корректно обрабатываются форматы `1x10^-8`, `10^{-9}`, `8.0E-8`.
    4.  **Результат:** Чистое число `float`. Если парсинг не удался, запись отбрасывается.

---

### **Шаг 3: Определение типа метрики (логарифмическая/линейная)**

-   **Цель:** Определить, как интерпретировать значение для правильной конвертации.
-   **Логика:** Запись считается логарифмической, если исходная `binding_metric` начинается с `p` или `log`.

---

### **Шаг 4: Нормализация названия метрики (`binding_metric`)**

-   **Цель:** Привести все варианты написания к одному из **четырех стандартов**: `IC50`, `Ki`, `Kd`, `EC50`.
-   **Логика:** Используются регулярные выражения для поиска совпадений (например, `ic-50`, `pIC50`, `IC 50` -> `IC50`). Записи с другими метриками отбрасываются.

---

### **Шаг 5: Конвертация в единый стандарт (нМ)**

-   **Цель:** Привести все значения к наномолям (`nM`).
-   **Логика:**
    -   **Для логарифмических:** Применяется формула `value = (10 ^ (-value)) * 10^9`.
    -   **Для линейных:**
        1.  **Нормализация `unit`:** `μM`, `micromolar` и т.д. приводятся к стандартным `nM`, `uM`, `mM`, `pM`.
        2.  **Конвертация:** Значение умножается на соответствующий коэффициент (`uM` -> `*1000`, `pM` -> `*0.001` и т.д.).
        3.  Записи с неподдерживаемыми `unit` отбрасываются.

---

### **Шаг 6: Фильтрация по диапазону значений**

-   **Цель:** Удалить нереалистичные или ошибочные данные.
-   **Логика:** Сохраняются только те записи, у которых финальное значение `value` находится в диапазоне **`[0.001, 100000]`** нМ.

---

### **Шаг 7: Фильтрация по имени молекулы (`molecule_name`)**

-   **Цель:** Удалить записи с неинформативными или слишком общими именами.
-   **Логика (применяется последовательно):**
    1.  **По длине:** Имена длиной 2 символа или меньше удаляются.
    2.  **По шаблону:** Удаляются имена, соответствующие общим паттернам, таким как `Compound 2`, `Example IX`, `compounds of formula I`.
    3.  **По списку:** Удаляются имена, точно совпадающие с элементами из списка общих названий (`antibody`, `nanobody` и их мн. число).

---

### **Интеграция в пайплайн**

Благодаря рефакторингу, интеграция в основной пайплайн выглядит просто:

```python
# В главном скрипте пайплайна
from data_normalization.normalize_data import normalize_data
from some_module import get_raw_data

# 1. Получить сырые данные с предыдущего шага
raw_data = get_raw_data() 

# 2. Вызвать функцию нормализации
cleaned_data = normalize_data(raw_data)

# 3. Передать очищенные данные на следующий этап
process_further(cleaned_data)
```
