{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "74b57a9bd78f4262"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T10:48:00.231935Z",
     "start_time": "2025-07-25T10:48:00.226637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PROJECT_ID = \"patent-reciever\"\n",
    "API_KEY = \"AIzaSyArL55vQDUGFaZV_j4CPHjRxGwEzBdjiYE\"\n",
    "GOOGLE_CRED = \"/home/vshepard/.cred/client_secret_421349657930-0050fvaco447f2jceo68n995vej35sfa.apps.googleusercontent.com.json\""
   ],
   "id": "7e8701159535409a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-25T10:40:04.245727Z",
     "start_time": "2025-07-25T10:40:02.609654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT name, SUM(number) as total_people\n",
    "    FROM `bigquery-public-data.usa_names.usa_1910_2013`\n",
    "    WHERE state = 'TX'\n",
    "    GROUP BY name, state\n",
    "    ORDER BY total_people DESC\n",
    "    LIMIT 20\n",
    "\"\"\"\n",
    "rows = client.query_and_wait(query)  # Make an API request.\n",
    "\n",
    "print(\"The query data:\")\n",
    "for row in rows:\n",
    "    # Row values can be accessed by field name or index.\n",
    "    print(\"name={}, count={}\".format(row[0], row[\"total_people\"]))"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 POST https://bigquery.googleapis.com/bigquery/v2/projects/sound-fastness-194720/queries?prettyPrint=false: Access to bigquery.googleapis.com is restricted from your billing country and was denied for projects/421349657930.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mForbidden\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 14\u001B[39m\n\u001B[32m      4\u001B[39m client = bigquery.Client(project=PROJECT_ID)\n\u001B[32m      6\u001B[39m query = \u001B[33m\"\"\"\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[33m    SELECT name, SUM(number) as total_people\u001B[39m\n\u001B[32m      8\u001B[39m \u001B[33m    FROM `bigquery-public-data.usa_names.usa_1910_2013`\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m     12\u001B[39m \u001B[33m    LIMIT 20\u001B[39m\n\u001B[32m     13\u001B[39m \u001B[33m\"\"\"\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m rows = \u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43mquery_and_wait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Make an API request.\u001B[39;00m\n\u001B[32m     16\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mThe query data:\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m rows:\n\u001B[32m     18\u001B[39m     \u001B[38;5;66;03m# Row values can be accessed by field name or index.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/work/hackaton_gero/lib/python3.12/site-packages/google/cloud/bigquery/client.py:3672\u001B[39m, in \u001B[36mClient.query_and_wait\u001B[39m\u001B[34m(self, query, job_config, location, project, api_timeout, wait_timeout, retry, job_retry, page_size, max_results)\u001B[39m\n\u001B[32m   3666\u001B[39m     _verify_job_config_type(job_config, QueryJobConfig)\n\u001B[32m   3668\u001B[39m job_config = _job_helpers.job_config_with_defaults(\n\u001B[32m   3669\u001B[39m     job_config, \u001B[38;5;28mself\u001B[39m._default_query_job_config\n\u001B[32m   3670\u001B[39m )\n\u001B[32m-> \u001B[39m\u001B[32m3672\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_job_helpers\u001B[49m\u001B[43m.\u001B[49m\u001B[43mquery_and_wait\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   3673\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   3674\u001B[39m \u001B[43m    \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3675\u001B[39m \u001B[43m    \u001B[49m\u001B[43mjob_config\u001B[49m\u001B[43m=\u001B[49m\u001B[43mjob_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3676\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3677\u001B[39m \u001B[43m    \u001B[49m\u001B[43mproject\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproject\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3678\u001B[39m \u001B[43m    \u001B[49m\u001B[43mapi_timeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mapi_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3679\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwait_timeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwait_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3680\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretry\u001B[49m\u001B[43m=\u001B[49m\u001B[43mretry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3681\u001B[39m \u001B[43m    \u001B[49m\u001B[43mjob_retry\u001B[49m\u001B[43m=\u001B[49m\u001B[43mjob_retry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3682\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpage_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpage_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3683\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_results\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_results\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3684\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/work/hackaton_gero/lib/python3.12/site-packages/google/cloud/bigquery/_job_helpers.py:567\u001B[39m, in \u001B[36mquery_and_wait\u001B[39m\u001B[34m(client, query, job_config, location, project, api_timeout, wait_timeout, retry, job_retry, page_size, max_results)\u001B[39m\n\u001B[32m    547\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m table.RowIterator(\n\u001B[32m    548\u001B[39m         client=client,\n\u001B[32m    549\u001B[39m         api_request=functools.partial(client._call_api, retry, timeout=api_timeout),\n\u001B[32m   (...)\u001B[39m\u001B[32m    563\u001B[39m         slot_millis=query_results.slot_millis,\n\u001B[32m    564\u001B[39m     )\n\u001B[32m    566\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m job_retry \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m567\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mjob_retry\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdo_query\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    568\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    569\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m do_query()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/work/hackaton_gero/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:294\u001B[39m, in \u001B[36mRetry.__call__.<locals>.retry_wrapped_func\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    290\u001B[39m target = functools.partial(func, *args, **kwargs)\n\u001B[32m    291\u001B[39m sleep_generator = exponential_sleep_generator(\n\u001B[32m    292\u001B[39m     \u001B[38;5;28mself\u001B[39m._initial, \u001B[38;5;28mself\u001B[39m._maximum, multiplier=\u001B[38;5;28mself\u001B[39m._multiplier\n\u001B[32m    293\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m294\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mretry_target\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    295\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    296\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_predicate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    297\u001B[39m \u001B[43m    \u001B[49m\u001B[43msleep_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    298\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    299\u001B[39m \u001B[43m    \u001B[49m\u001B[43mon_error\u001B[49m\u001B[43m=\u001B[49m\u001B[43mon_error\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    300\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/work/hackaton_gero/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:156\u001B[39m, in \u001B[36mretry_target\u001B[39m\u001B[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001B[39m\n\u001B[32m    152\u001B[39m \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[32m    153\u001B[39m \u001B[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001B[39;00m\n\u001B[32m    154\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m    155\u001B[39m     \u001B[38;5;66;03m# defer to shared logic for handling errors\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m156\u001B[39m     next_sleep = \u001B[43m_retry_error_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    157\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    158\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdeadline\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    159\u001B[39m \u001B[43m        \u001B[49m\u001B[43msleep_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    160\u001B[39m \u001B[43m        \u001B[49m\u001B[43merror_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    161\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpredicate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    162\u001B[39m \u001B[43m        \u001B[49m\u001B[43mon_error\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    163\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexception_factory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    164\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    165\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    166\u001B[39m     \u001B[38;5;66;03m# if exception not raised, sleep before next attempt\u001B[39;00m\n\u001B[32m    167\u001B[39m     time.sleep(next_sleep)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/work/hackaton_gero/lib/python3.12/site-packages/google/api_core/retry/retry_base.py:214\u001B[39m, in \u001B[36m_retry_error_helper\u001B[39m\u001B[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001B[39m\n\u001B[32m    208\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m predicate_fn(exc):\n\u001B[32m    209\u001B[39m     final_exc, source_exc = exc_factory_fn(\n\u001B[32m    210\u001B[39m         error_list,\n\u001B[32m    211\u001B[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001B[32m    212\u001B[39m         original_timeout,\n\u001B[32m    213\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m214\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m final_exc \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msource_exc\u001B[39;00m\n\u001B[32m    215\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m on_error_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    216\u001B[39m     on_error_fn(exc)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/work/hackaton_gero/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:147\u001B[39m, in \u001B[36mretry_target\u001B[39m\u001B[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001B[39m\n\u001B[32m    145\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m    146\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m147\u001B[39m         result = \u001B[43mtarget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    148\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m inspect.isawaitable(result):\n\u001B[32m    149\u001B[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/work/hackaton_gero/lib/python3.12/site-packages/google/cloud/bigquery/_job_helpers.py:505\u001B[39m, in \u001B[36mquery_and_wait.<locals>.do_query\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    503\u001B[39m \u001B[38;5;66;03m# For easier testing, handle the retries ourselves.\u001B[39;00m\n\u001B[32m    504\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m retry \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m505\u001B[39m     response = \u001B[43mretry\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_call_api\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    506\u001B[39m \u001B[43m        \u001B[49m\u001B[43mretry\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# We're calling the retry decorator ourselves.\u001B[39;49;00m\n\u001B[32m    507\u001B[39m \u001B[43m        \u001B[49m\u001B[43mspan_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mBigQuery.query\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    508\u001B[39m \u001B[43m        \u001B[49m\u001B[43mspan_attributes\u001B[49m\u001B[43m=\u001B[49m\u001B[43mspan_attributes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    509\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mPOST\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    510\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    511\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrequest_body\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    512\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mapi_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    513\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    514\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    515\u001B[39m     response = client._call_api(\n\u001B[32m    516\u001B[39m         retry=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    517\u001B[39m         span_name=\u001B[33m\"\u001B[39m\u001B[33mBigQuery.query\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    522\u001B[39m         timeout=api_timeout,\n\u001B[32m    523\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/work/hackaton_gero/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:294\u001B[39m, in \u001B[36mRetry.__call__.<locals>.retry_wrapped_func\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    290\u001B[39m target = functools.partial(func, *args, **kwargs)\n\u001B[32m    291\u001B[39m sleep_generator = exponential_sleep_generator(\n\u001B[32m    292\u001B[39m     \u001B[38;5;28mself\u001B[39m._initial, \u001B[38;5;28mself\u001B[39m._maximum, multiplier=\u001B[38;5;28mself\u001B[39m._multiplier\n\u001B[32m    293\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m294\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mretry_target\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    295\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    296\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_predicate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    297\u001B[39m \u001B[43m    \u001B[49m\u001B[43msleep_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    298\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    299\u001B[39m \u001B[43m    \u001B[49m\u001B[43mon_error\u001B[49m\u001B[43m=\u001B[49m\u001B[43mon_error\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    300\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/work/hackaton_gero/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:156\u001B[39m, in \u001B[36mretry_target\u001B[39m\u001B[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001B[39m\n\u001B[32m    152\u001B[39m \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[32m    153\u001B[39m \u001B[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001B[39;00m\n\u001B[32m    154\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m    155\u001B[39m     \u001B[38;5;66;03m# defer to shared logic for handling errors\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m156\u001B[39m     next_sleep = \u001B[43m_retry_error_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    157\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    158\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdeadline\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    159\u001B[39m \u001B[43m        \u001B[49m\u001B[43msleep_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    160\u001B[39m \u001B[43m        \u001B[49m\u001B[43merror_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    161\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpredicate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    162\u001B[39m \u001B[43m        \u001B[49m\u001B[43mon_error\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    163\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexception_factory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    164\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    165\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    166\u001B[39m     \u001B[38;5;66;03m# if exception not raised, sleep before next attempt\u001B[39;00m\n\u001B[32m    167\u001B[39m     time.sleep(next_sleep)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/work/hackaton_gero/lib/python3.12/site-packages/google/api_core/retry/retry_base.py:214\u001B[39m, in \u001B[36m_retry_error_helper\u001B[39m\u001B[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001B[39m\n\u001B[32m    208\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m predicate_fn(exc):\n\u001B[32m    209\u001B[39m     final_exc, source_exc = exc_factory_fn(\n\u001B[32m    210\u001B[39m         error_list,\n\u001B[32m    211\u001B[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001B[32m    212\u001B[39m         original_timeout,\n\u001B[32m    213\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m214\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m final_exc \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msource_exc\u001B[39;00m\n\u001B[32m    215\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m on_error_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    216\u001B[39m     on_error_fn(exc)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/work/hackaton_gero/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:147\u001B[39m, in \u001B[36mretry_target\u001B[39m\u001B[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001B[39m\n\u001B[32m    145\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m    146\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m147\u001B[39m         result = \u001B[43mtarget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    148\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m inspect.isawaitable(result):\n\u001B[32m    149\u001B[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/work/hackaton_gero/lib/python3.12/site-packages/google/cloud/bigquery/client.py:859\u001B[39m, in \u001B[36mClient._call_api\u001B[39m\u001B[34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001B[39m\n\u001B[32m    855\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m span_name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    856\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m create_span(\n\u001B[32m    857\u001B[39m         name=span_name, attributes=span_attributes, client=\u001B[38;5;28mself\u001B[39m, job_ref=job_ref\n\u001B[32m    858\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m859\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    861\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m call()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/work/hackaton_gero/lib/python3.12/site-packages/google/cloud/_http/__init__.py:494\u001B[39m, in \u001B[36mJSONConnection.api_request\u001B[39m\u001B[34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001B[39m\n\u001B[32m    482\u001B[39m response = \u001B[38;5;28mself\u001B[39m._make_request(\n\u001B[32m    483\u001B[39m     method=method,\n\u001B[32m    484\u001B[39m     url=url,\n\u001B[32m   (...)\u001B[39m\u001B[32m    490\u001B[39m     extra_api_info=extra_api_info,\n\u001B[32m    491\u001B[39m )\n\u001B[32m    493\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[32m200\u001B[39m <= response.status_code < \u001B[32m300\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m494\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exceptions.from_http_response(response)\n\u001B[32m    496\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m expect_json \u001B[38;5;129;01mand\u001B[39;00m response.content:\n\u001B[32m    497\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m response.json()\n",
      "\u001B[31mForbidden\u001B[39m: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/sound-fastness-194720/queries?prettyPrint=false: Access to bigquery.googleapis.com is restricted from your billing country and was denied for projects/421349657930."
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T10:48:45.210381Z",
     "start_time": "2025-07-25T10:48:44.463243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from google.cloud import bigquery\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/home/vshepard/.config/gcloud/application_default_credentials.json\"\n",
    "\n",
    "bq_client = bigquery.Client(project=PROJECT_ID)"
   ],
   "id": "552bd8e1118b0cb6",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T10:55:22.337776Z",
     "start_time": "2025-07-25T10:55:22.332387Z"
    }
   },
   "cell_type": "code",
   "source": "text_pattern = r\"\\b(IC50|IC[\\s_\\-]*50|IC₅₀|ic50|ic[\\s_\\-]*50|Ki|ki|K[iI]|k[iI]|Kd|kd|K[dD]|k[dD]|EC50|EC[\\s_\\-]*50|EC₅₀|ec50|ec[\\s_\\-]*50|pIC50|pIC[\\s_\\-]*50|pIC₅₀|pic50|pic[\\s_\\-]*50|pEC50|pEC[\\s_\\-]*50|pEC₅₀|pec50|pec[\\s_\\-]*50|pKi|pki|pK[iI]|pk[iI]|pKd|pkd|pK[dD]|pk[dD]|logIC50|log[\\s]*IC50|log[\\s]*\\([\\s]*IC50[\\s]*\\)|-log[\\s]*\\([\\s]*IC50[\\s]*\\)|logKi|log[\\s]*Ki|log[\\s]*\\([\\s]*Ki[\\s]*\\)|-log[\\s]*\\([\\s]*Ki[\\s]*\\)|logKd|log[\\s]*Kd|log[\\s]*\\([\\s]*Kd[\\s]*\\)|-log[\\s]*\\([\\s]*Kd[\\s]*\\)|logEC50|log[\\s]*EC50|log[\\s]*\\([\\s]*EC50[\\s]*\\)|-log[\\s]*\\([\\s]*EC50[\\s]*\\)|inhibition[\\s\\-]*constant|dissociation[\\s\\-]*constant|binding[\\s\\-]*constant|half[\\s\\-]*maximal[\\s\\-]*inhibitory[\\s\\-]*concentration|half[\\s\\-]*maximal[\\s\\-]*effective[\\s\\-]*concentration|binding[\\s\\-]*assay)\\b\"\n",
   "id": "c68bdb8ff970edf8",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T10:55:24.905819Z",
     "start_time": "2025-07-25T10:55:24.901142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sql_query = f\"\"\"\n",
    "SELECT\n",
    "    publication_number,\n",
    "    title,\n",
    "    abstract,\n",
    "    claims_text,\n",
    "    assignee,\n",
    "    ARRAY(SELECT code FROM UNNEST(ipc_classifications)) AS ipc_codes,\n",
    "    publication_date\n",
    "FROM\n",
    "    `bigquery-public-data.patents.publications`\n",
    "WHERE\n",
    "    (\n",
    "        REGEXP_CONTAINS(abstract, r\"{text_pattern}\") OR\n",
    "        REGEXP_CONTAINS(title, r\"{text_pattern}\") OR\n",
    "        REGEXP_CONTAINS(claims_text, r\"{text_pattern}\")\n",
    "    )\n",
    "    AND\n",
    "    EXISTS(\n",
    "        SELECT 1\n",
    "        FROM UNNEST(ipc_classifications) AS ipc\n",
    "        WHERE ipc.code LIKE 'A61K%' OR ipc.code LIKE 'A61P%'\n",
    "    )\n",
    "LIMIT 100 -- Limit to 100 results for demonstration. Remove or increase for more results.\n",
    "\"\"\""
   ],
   "id": "e9cba708753e4b30",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T10:56:15.265886Z",
     "start_time": "2025-07-25T10:56:14.927266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Querying BigQuery with pattern and IPC A61K/A61P...\")\n",
    "\n",
    "try:\n",
    "    query_job = client.query(sql_query)\n",
    "    rows = query_job.result()\n",
    "\n",
    "    print(\"\\n--- Found Patents ---\")\n",
    "    patent_count = 0\n",
    "    for row in rows:\n",
    "        patent_count += 1\n",
    "        print(f\"Publication Number: {row.publication_number}\")\n",
    "        print(f\"Title: {row.title}\")\n",
    "        print(f\"IPC Codes: {', '.join(row.ipc_codes)}\")\n",
    "        print(f\"Publication Date: {row.publication_date}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "    if patent_count == 0:\n",
    "        print(\"No patents found matching the criteria.\")\n",
    "    else:\n",
    "        print(f\"\\nTotal patents found: {patent_count}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during query execution: {e}\")\n",
    "    print(\"Please check your query, permissions, and project ID.\")\n"
   ],
   "id": "5b80da210b5f77d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying BigQuery with pattern and IPC A61K/A61P...\n",
      "An error occurred during query execution: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/sound-fastness-194720/jobs?prettyPrint=false: Access to bigquery.googleapis.com is restricted from your billing country and was denied for projects/421349657930.\n",
      "\n",
      "Location: None\n",
      "Job ID: 568252f1-464a-4970-b953-d8ae82132097\n",
      "\n",
      "Please check your query, permissions, and project ID.\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T22:48:44.178712Z",
     "start_time": "2025-07-28T22:48:44.174649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"service-cred.json\"\n",
    "PROJECT_ID = \"patent-reciever\"\n"
   ],
   "id": "935241dd33170612",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T22:51:15.035394Z",
     "start_time": "2025-07-28T22:51:15.031429Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "550d24b5f1b984cc",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T23:06:50.404417Z",
     "start_time": "2025-07-28T23:06:02.870982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas_gbq\n",
    "df = pandas_gbq.read_gbq(query, project_id=PROJECT_ID)\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    t1.publication_number,\n",
    "    description.text AS description_text,\n",
    "    t1.publication_date\n",
    "FROM\n",
    "    bigquery-public-data.patents.publications AS t1,\n",
    "    UNNEST(t1.title_localized) AS title,\n",
    "    UNNEST(t1.description_localized) AS description\n",
    "WHERE\n",
    "    REGEXP_CONTAINS(description.text, r\"(IC50|IC[\\s_\\-]*50|IC₅₀|ic50|ic[\\s_\\-]*50|Ki|ki|K[iI]|k[iI]|Kd|kd|K[dD]|k[dD]|EC50|EC[\\s_\\-]*50|EC₅₀|ec50|ec[\\s_\\-]*50|pIC50|pIC[\\s_\\-]*50|pIC₅₀|pic50|pic[\\s_\\-]*50|pEC50|pEC[\\s_\\-]*50|pEC₅₀|pec50|pec[\\s_\\-]*50|pKi|pki|pK[iI]|pk[iI]|pKd|pkd|pK[dD]|pk[dD]|logIC50|log[\\s]*IC50|log[\\s]*\\([\\s]*IC50[\\s]*\\)|-log[\\s]*\\([\\s]*IC50[\\s]*\\)|logKi|log[\\s]*Ki|log[\\s]*\\([\\s]*Ki[\\s]*\\)|-log[\\s]*\\([\\s]*Ki[\\s]*\\)|logKd|log[\\s]*Kd|log[\\s]*\\([\\s]*Kd[\\s]*\\)|-log[\\s]*\\([\\s]*Kd[\\s]*\\)|logEC50|log[\\s]*EC50|log[\\s]*\\([\\s]*EC50[\\s]*\\)|-log[\\s]*\\([\\s]*EC50[\\s]*\\)|inhibition[\\s\\-]*constant|dissociation[\\s\\-]*constant|binding[\\s\\-]*constant|half[\\s\\-]*maximal[\\s\\-]*inhibitory[\\s\\-]*concentration|half[\\s\\-]*maximal[\\s\\-]*effective[\\s\\-]*concentration|binding[\\s\\-]*assay)\")\n",
    "    AND\n",
    "    EXISTS(\n",
    "        SELECT 1\n",
    "        FROM UNNEST(t1.ipc) AS ipc_code_record\n",
    "        WHERE ipc_code_record.code LIKE 'A61K%' OR ipc_code_record.code LIKE 'A61P%'\n",
    "    )\n",
    "    order by 1\n",
    "    limit 1000;\n",
    "\"\"\"\n",
    "df.to_parquet(\"patents_filtered.parquet\", index=False)\n",
    "\n",
    "print(\"✅ Parquet file saved as 'patents_filtered.parquet'\")\n",
    "print(len(df))\n"
   ],
   "id": "19c75f6467665ba",
   "outputs": [
    {
     "ename": "GenericGBQException",
     "evalue": "Reason: 403 GET https://bigquery.googleapis.com/bigquery/v2/projects/patent-reciever/queries/job_yg3bcoca5PCkbVFtjoepbIcaT-JT?maxResults=0&location=US&prettyPrint=false: Response too large to return. Consider specifying a destination table in your job configuration. For more details, see https://cloud.google.com/bigquery/troubleshooting-errors\n\nLocation: US\nJob ID: job_yg3bcoca5PCkbVFtjoepbIcaT-JT\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mForbidden\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas_gbq/query.py:85\u001B[0m, in \u001B[0;36mtry_query\u001B[0;34m(connector, query_fn)\u001B[0m\n\u001B[1;32m     84\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRequesting query... \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 85\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mquery_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m concurrent\u001B[38;5;241m.\u001B[39mfutures\u001B[38;5;241m.\u001B[39mTimeoutError \u001B[38;5;28;01mas\u001B[39;00m ex:\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/google/cloud/bigquery/client.py:3672\u001B[0m, in \u001B[0;36mClient.query_and_wait\u001B[0;34m(self, query, job_config, location, project, api_timeout, wait_timeout, retry, job_retry, page_size, max_results)\u001B[0m\n\u001B[1;32m   3668\u001B[0m job_config \u001B[38;5;241m=\u001B[39m _job_helpers\u001B[38;5;241m.\u001B[39mjob_config_with_defaults(\n\u001B[1;32m   3669\u001B[0m     job_config, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_default_query_job_config\n\u001B[1;32m   3670\u001B[0m )\n\u001B[0;32m-> 3672\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_job_helpers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery_and_wait\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3673\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3674\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3675\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjob_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjob_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3676\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlocation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3677\u001B[0m \u001B[43m    \u001B[49m\u001B[43mproject\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproject\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3678\u001B[0m \u001B[43m    \u001B[49m\u001B[43mapi_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3679\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwait_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwait_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3680\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3681\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjob_retry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjob_retry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3682\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpage_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpage_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3683\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_results\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_results\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3684\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/google/cloud/bigquery/_job_helpers.py:567\u001B[0m, in \u001B[0;36mquery_and_wait\u001B[0;34m(client, query, job_config, location, project, api_timeout, wait_timeout, retry, job_retry, page_size, max_results)\u001B[0m\n\u001B[1;32m    566\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m job_retry \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 567\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mjob_retry\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdo_query\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:294\u001B[0m, in \u001B[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    291\u001B[0m sleep_generator \u001B[38;5;241m=\u001B[39m exponential_sleep_generator(\n\u001B[1;32m    292\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initial, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maximum, multiplier\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_multiplier\n\u001B[1;32m    293\u001B[0m )\n\u001B[0;32m--> 294\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mretry_target\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    295\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    296\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predicate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    297\u001B[0m \u001B[43m    \u001B[49m\u001B[43msleep_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    298\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    299\u001B[0m \u001B[43m    \u001B[49m\u001B[43mon_error\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mon_error\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    300\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:156\u001B[0m, in \u001B[0;36mretry_target\u001B[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001B[0m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    155\u001B[0m     \u001B[38;5;66;03m# defer to shared logic for handling errors\u001B[39;00m\n\u001B[0;32m--> 156\u001B[0m     next_sleep \u001B[38;5;241m=\u001B[39m \u001B[43m_retry_error_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdeadline\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43msleep_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpredicate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m        \u001B[49m\u001B[43mon_error\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexception_factory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;66;03m# if exception not raised, sleep before next attempt\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:214\u001B[0m, in \u001B[0;36m_retry_error_helper\u001B[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001B[0m\n\u001B[1;32m    209\u001B[0m     final_exc, source_exc \u001B[38;5;241m=\u001B[39m exc_factory_fn(\n\u001B[1;32m    210\u001B[0m         error_list,\n\u001B[1;32m    211\u001B[0m         RetryFailureReason\u001B[38;5;241m.\u001B[39mNON_RETRYABLE_ERROR,\n\u001B[1;32m    212\u001B[0m         original_timeout,\n\u001B[1;32m    213\u001B[0m     )\n\u001B[0;32m--> 214\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m final_exc \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msource_exc\u001B[39;00m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m on_error_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:147\u001B[0m, in \u001B[0;36mretry_target\u001B[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001B[0m\n\u001B[1;32m    146\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 147\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mtarget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39misawaitable(result):\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/google/cloud/bigquery/_job_helpers.py:538\u001B[0m, in \u001B[0;36mquery_and_wait.<locals>.do_query\u001B[0;34m()\u001B[0m\n\u001B[1;32m    533\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m more_pages \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m query_results\u001B[38;5;241m.\u001B[39mcomplete:\n\u001B[1;32m    534\u001B[0m     \u001B[38;5;66;03m# TODO(swast): Avoid a call to jobs.get in some cases (few\u001B[39;00m\n\u001B[1;32m    535\u001B[0m     \u001B[38;5;66;03m# remaining pages) by waiting for the query to finish and calling\u001B[39;00m\n\u001B[1;32m    536\u001B[0m     \u001B[38;5;66;03m# client._list_rows_from_query_results directly. Need to update\u001B[39;00m\n\u001B[1;32m    537\u001B[0m     \u001B[38;5;66;03m# RowIterator to fetch destination table via the job ID if needed.\u001B[39;00m\n\u001B[0;32m--> 538\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_wait_or_cancel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    539\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_to_query_job\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjob_config\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    540\u001B[0m \u001B[43m        \u001B[49m\u001B[43mapi_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    541\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwait_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwait_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    542\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    543\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpage_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpage_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    544\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_results\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_results\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    547\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m table\u001B[38;5;241m.\u001B[39mRowIterator(\n\u001B[1;32m    548\u001B[0m     client\u001B[38;5;241m=\u001B[39mclient,\n\u001B[1;32m    549\u001B[0m     api_request\u001B[38;5;241m=\u001B[39mfunctools\u001B[38;5;241m.\u001B[39mpartial(client\u001B[38;5;241m.\u001B[39m_call_api, retry, timeout\u001B[38;5;241m=\u001B[39mapi_timeout),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    563\u001B[0m     slot_millis\u001B[38;5;241m=\u001B[39mquery_results\u001B[38;5;241m.\u001B[39mslot_millis,\n\u001B[1;32m    564\u001B[0m )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/google/cloud/bigquery/_job_helpers.py:621\u001B[0m, in \u001B[0;36m_wait_or_cancel\u001B[0;34m(job, api_timeout, wait_timeout, retry, page_size, max_results)\u001B[0m\n\u001B[1;32m    620\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    622\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpage_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpage_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    623\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_results\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_results\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    624\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    625\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwait_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    626\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;66;03m# Attempt to cancel the job since we can't return the results.\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1704\u001B[0m, in \u001B[0;36mQueryJob.result\u001B[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001B[0m\n\u001B[1;32m   1701\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m remaining_timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1702\u001B[0m     \u001B[38;5;66;03m# Since is_job_done() calls jobs.getQueryResults, which is a\u001B[39;00m\n\u001B[1;32m   1703\u001B[0m     \u001B[38;5;66;03m# long-running API, don't delay the next request at all.\u001B[39;00m\n\u001B[0;32m-> 1704\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mis_job_done\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1705\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1673\u001B[0m, in \u001B[0;36mQueryJob.result.<locals>.is_job_done\u001B[0;34m()\u001B[0m\n\u001B[1;32m   1669\u001B[0m \u001B[38;5;66;03m# Call jobs.getQueryResults with max results set to 0 just to\u001B[39;00m\n\u001B[1;32m   1670\u001B[0m \u001B[38;5;66;03m# wait for the query to finish. Unlike most methods,\u001B[39;00m\n\u001B[1;32m   1671\u001B[0m \u001B[38;5;66;03m# jobs.getQueryResults hangs as long as it can to ensure we\u001B[39;00m\n\u001B[1;32m   1672\u001B[0m \u001B[38;5;66;03m# know when the query has finished as soon as possible.\u001B[39;00m\n\u001B[0;32m-> 1673\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reload_query_results\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mreload_query_results_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1675\u001B[0m \u001B[38;5;66;03m# Even if the query is finished now according to\u001B[39;00m\n\u001B[1;32m   1676\u001B[0m \u001B[38;5;66;03m# jobs.getQueryResults, we'll want to reload the job status if\u001B[39;00m\n\u001B[1;32m   1677\u001B[0m \u001B[38;5;66;03m# it's not already DONE.\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1467\u001B[0m, in \u001B[0;36mQueryJob._reload_query_results\u001B[0;34m(self, retry, timeout, page_size, start_index)\u001B[0m\n\u001B[1;32m   1465\u001B[0m         transport_timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1467\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_query_results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_query_results\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1468\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjob_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1469\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1470\u001B[0m \u001B[43m    \u001B[49m\u001B[43mproject\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproject\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1471\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout_ms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_ms\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1472\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlocation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlocation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1473\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransport_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1474\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpage_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpage_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1475\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstart_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstart_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1476\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/google/cloud/bigquery/client.py:2111\u001B[0m, in \u001B[0;36mClient._get_query_results\u001B[0;34m(self, job_id, retry, project, timeout_ms, location, timeout, page_size, start_index)\u001B[0m\n\u001B[1;32m   2110\u001B[0m span_attributes \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpath\u001B[39m\u001B[38;5;124m\"\u001B[39m: path}\n\u001B[0;32m-> 2111\u001B[0m resource \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_api\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2112\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2113\u001B[0m \u001B[43m    \u001B[49m\u001B[43mspan_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mBigQuery.getQueryResults\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2114\u001B[0m \u001B[43m    \u001B[49m\u001B[43mspan_attributes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mspan_attributes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2115\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGET\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2116\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2117\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquery_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2118\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2119\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2120\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _QueryResults\u001B[38;5;241m.\u001B[39mfrom_api_repr(resource)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/google/cloud/bigquery/client.py:859\u001B[0m, in \u001B[0;36mClient._call_api\u001B[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001B[0m\n\u001B[1;32m    856\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m create_span(\n\u001B[1;32m    857\u001B[0m         name\u001B[38;5;241m=\u001B[39mspan_name, attributes\u001B[38;5;241m=\u001B[39mspan_attributes, client\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, job_ref\u001B[38;5;241m=\u001B[39mjob_ref\n\u001B[1;32m    858\u001B[0m     ):\n\u001B[0;32m--> 859\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    861\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m call()\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:294\u001B[0m, in \u001B[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    291\u001B[0m sleep_generator \u001B[38;5;241m=\u001B[39m exponential_sleep_generator(\n\u001B[1;32m    292\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initial, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maximum, multiplier\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_multiplier\n\u001B[1;32m    293\u001B[0m )\n\u001B[0;32m--> 294\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mretry_target\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    295\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    296\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predicate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    297\u001B[0m \u001B[43m    \u001B[49m\u001B[43msleep_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    298\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    299\u001B[0m \u001B[43m    \u001B[49m\u001B[43mon_error\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mon_error\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    300\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:156\u001B[0m, in \u001B[0;36mretry_target\u001B[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001B[0m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    155\u001B[0m     \u001B[38;5;66;03m# defer to shared logic for handling errors\u001B[39;00m\n\u001B[0;32m--> 156\u001B[0m     next_sleep \u001B[38;5;241m=\u001B[39m \u001B[43m_retry_error_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdeadline\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43msleep_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpredicate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m        \u001B[49m\u001B[43mon_error\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexception_factory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;66;03m# if exception not raised, sleep before next attempt\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:214\u001B[0m, in \u001B[0;36m_retry_error_helper\u001B[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001B[0m\n\u001B[1;32m    209\u001B[0m     final_exc, source_exc \u001B[38;5;241m=\u001B[39m exc_factory_fn(\n\u001B[1;32m    210\u001B[0m         error_list,\n\u001B[1;32m    211\u001B[0m         RetryFailureReason\u001B[38;5;241m.\u001B[39mNON_RETRYABLE_ERROR,\n\u001B[1;32m    212\u001B[0m         original_timeout,\n\u001B[1;32m    213\u001B[0m     )\n\u001B[0;32m--> 214\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m final_exc \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msource_exc\u001B[39;00m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m on_error_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:147\u001B[0m, in \u001B[0;36mretry_target\u001B[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001B[0m\n\u001B[1;32m    146\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 147\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mtarget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39misawaitable(result):\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/google/cloud/_http/__init__.py:494\u001B[0m, in \u001B[0;36mJSONConnection.api_request\u001B[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001B[0m\n\u001B[1;32m    493\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;241m200\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m300\u001B[39m:\n\u001B[0;32m--> 494\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mfrom_http_response(response)\n\u001B[1;32m    496\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m expect_json \u001B[38;5;129;01mand\u001B[39;00m response\u001B[38;5;241m.\u001B[39mcontent:\n",
      "\u001B[0;31mForbidden\u001B[0m: 403 GET https://bigquery.googleapis.com/bigquery/v2/projects/patent-reciever/queries/job_yg3bcoca5PCkbVFtjoepbIcaT-JT?maxResults=0&location=US&prettyPrint=false: Response too large to return. Consider specifying a destination table in your job configuration. For more details, see https://cloud.google.com/bigquery/troubleshooting-errors\n\nLocation: US\nJob ID: job_yg3bcoca5PCkbVFtjoepbIcaT-JT\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mGenericGBQException\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas_gbq\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpandas_gbq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_gbq\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mproject_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mPROJECT_ID\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124mSELECT\u001B[39m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124m    t1.publication_number,\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;124m    limit 3000;\u001B[39m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m     24\u001B[0m df\u001B[38;5;241m.\u001B[39mto_parquet(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpatents_filtered.parquet\u001B[39m\u001B[38;5;124m\"\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas_gbq/gbq.py:322\u001B[0m, in \u001B[0;36mread_gbq\u001B[0;34m(query_or_table, project_id, index_col, columns, reauth, auth_local_webserver, dialect, location, configuration, credentials, use_bqstorage_api, max_results, verbose, private_key, progress_bar_type, dtypes, auth_redirect_uri, client_id, client_secret, col_order, bigquery_client)\u001B[0m\n\u001B[1;32m    306\u001B[0m connector \u001B[38;5;241m=\u001B[39m GbqConnector(\n\u001B[1;32m    307\u001B[0m     project_id,\n\u001B[1;32m    308\u001B[0m     reauth\u001B[38;5;241m=\u001B[39mreauth,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    318\u001B[0m     bigquery_client\u001B[38;5;241m=\u001B[39mbigquery_client,\n\u001B[1;32m    319\u001B[0m )\n\u001B[1;32m    321\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _is_query(query_or_table):\n\u001B[0;32m--> 322\u001B[0m     final_df \u001B[38;5;241m=\u001B[39m \u001B[43mconnector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_query\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    323\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery_or_table\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    324\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfiguration\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfiguration\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_results\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_results\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    326\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprogress_bar_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    327\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtypes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    328\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    330\u001B[0m     final_df \u001B[38;5;241m=\u001B[39m connector\u001B[38;5;241m.\u001B[39mdownload_table(\n\u001B[1;32m    331\u001B[0m         query_or_table,\n\u001B[1;32m    332\u001B[0m         max_results\u001B[38;5;241m=\u001B[39mmax_results,\n\u001B[1;32m    333\u001B[0m         progress_bar_type\u001B[38;5;241m=\u001B[39mprogress_bar_type,\n\u001B[1;32m    334\u001B[0m         dtypes\u001B[38;5;241m=\u001B[39mdtypes,\n\u001B[1;32m    335\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas_gbq/gbq_connector.py:240\u001B[0m, in \u001B[0;36mGbqConnector.run_query\u001B[0;34m(self, query, max_results, progress_bar_type, **kwargs)\u001B[0m\n\u001B[1;32m    237\u001B[0m job_config \u001B[38;5;241m=\u001B[39m bigquery\u001B[38;5;241m.\u001B[39mQueryJobConfig\u001B[38;5;241m.\u001B[39mfrom_api_repr(job_config_dict)\n\u001B[1;32m    239\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m FEATURES\u001B[38;5;241m.\u001B[39mbigquery_has_query_and_wait:\n\u001B[0;32m--> 240\u001B[0m     rows_iter \u001B[38;5;241m=\u001B[39m \u001B[43mpandas_gbq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery_and_wait_via_client_library\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    241\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    242\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    244\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlocation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    245\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproject_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproject_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    246\u001B[0m \u001B[43m        \u001B[49m\u001B[43mjob_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjob_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    247\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_results\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_results\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    248\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout_ms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_ms\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    249\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    251\u001B[0m     rows_iter \u001B[38;5;241m=\u001B[39m pandas_gbq\u001B[38;5;241m.\u001B[39mquery\u001B[38;5;241m.\u001B[39mquery_and_wait(\n\u001B[1;32m    252\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    253\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    259\u001B[0m         timeout_ms\u001B[38;5;241m=\u001B[39mtimeout_ms,\n\u001B[1;32m    260\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas_gbq/query.py:198\u001B[0m, in \u001B[0;36mquery_and_wait_via_client_library\u001B[0;34m(connector, client, query, job_config, location, project_id, max_results, timeout_ms)\u001B[0m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mquery_and_wait_via_client_library\u001B[39m(\n\u001B[1;32m    188\u001B[0m     connector,\n\u001B[1;32m    189\u001B[0m     client: bigquery\u001B[38;5;241m.\u001B[39mClient,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    196\u001B[0m     timeout_ms: Optional[\u001B[38;5;28mint\u001B[39m],\n\u001B[1;32m    197\u001B[0m ):\n\u001B[0;32m--> 198\u001B[0m     rows_iter \u001B[38;5;241m=\u001B[39m \u001B[43mtry_query\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconnector\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    200\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunctools\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    201\u001B[0m \u001B[43m            \u001B[49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery_and_wait\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m            \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    203\u001B[0m \u001B[43m            \u001B[49m\u001B[43mjob_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjob_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    204\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlocation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    205\u001B[0m \u001B[43m            \u001B[49m\u001B[43mproject\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproject_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    206\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmax_results\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_results\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    207\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwait_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_ms\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1000.0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtimeout_ms\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    208\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    209\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    210\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mQuery done.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    211\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m rows_iter\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas_gbq/query.py:99\u001B[0m, in \u001B[0;36mtry_query\u001B[0;34m(connector, query_fn)\u001B[0m\n\u001B[1;32m     94\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m pandas_gbq\u001B[38;5;241m.\u001B[39mexceptions\u001B[38;5;241m.\u001B[39mAccessDenied(\n\u001B[1;32m     95\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe credentials have been revoked or expired, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     96\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplease re-run the application to re-authorize: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mex\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     97\u001B[0m         )\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m connector\u001B[38;5;241m.\u001B[39mhttp_error \u001B[38;5;28;01mas\u001B[39;00m ex:\n\u001B[0;32m---> 99\u001B[0m     \u001B[43mconnector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess_http_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43mex\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas_gbq/gbq_connector.py:174\u001B[0m, in \u001B[0;36mGbqConnector.process_http_error\u001B[0;34m(ex)\u001B[0m\n\u001B[1;32m    172\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m TableCreationError(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReason: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00merror_message\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 174\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m GenericGBQException(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReason: \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(ex)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mex\u001B[39;00m\n",
      "\u001B[0;31mGenericGBQException\u001B[0m: Reason: 403 GET https://bigquery.googleapis.com/bigquery/v2/projects/patent-reciever/queries/job_yg3bcoca5PCkbVFtjoepbIcaT-JT?maxResults=0&location=US&prettyPrint=false: Response too large to return. Consider specifying a destination table in your job configuration. For more details, see https://cloud.google.com/bigquery/troubleshooting-errors\n\nLocation: US\nJob ID: job_yg3bcoca5PCkbVFtjoepbIcaT-JT\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T22:48:06.800166Z",
     "start_time": "2025-07-28T22:47:55.855120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test connection to bigquery\n",
    "import sys\n",
    "import db_dtypes\n",
    "import pandas_gbq\n",
    "print(\"Python:\", sys.executable)\n",
    "print(\"db_dtypes module:\", db_dtypes)\n",
    "print(\"pandas_gbq version:\", pandas_gbq.__version__)\n",
    "\n",
    "query = \"SELECT name FROM `bigquery-public-data.usa_names.usa_1910_2013` WHERE state='TX' LIMIT 1\"\n",
    "project_id = \"patent-reciever\"\n",
    "df = pandas_gbq.read_gbq(query, project_id=project_id)\n",
    "print(df.head())\n"
   ],
   "id": "ff3c2b27abfc2d12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: /usr/bin/python3.10\n",
      "db_dtypes module: <module 'db_dtypes' from '/home/vshepard/.local/lib/python3.10/site-packages/db_dtypes/__init__.py'>\n",
      "pandas_gbq version: 0.29.2\n",
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=262006177488-3425ks60hkk80fssi9vpohv88g6q1iqd.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fbigquery&state=ZFeazdaoOrkcbIEfqPjUgMVYWyGFZn&prompt=consent&access_type=offline\n",
      "Downloading: 100%|\u001B[32m██████████\u001B[0m|\n",
      "      name\n",
      "0  Pauline\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T23:28:48.575058Z",
     "start_time": "2025-07-28T23:27:14.340684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import uuid\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "client = bigquery.Client()\n",
    "PROJECT_ID = \"patent-reciever\"\n",
    "QUERY = \"\"\"\n",
    "SELECT\n",
    "    t1.publication_number,\n",
    "    description.text AS description_text,\n",
    "    t1.publication_date\n",
    "FROM\n",
    "    `bigquery-public-data.patents.publications` AS t1,\n",
    "    UNNEST(t1.description_localized) AS description\n",
    "WHERE\n",
    "    REGEXP_CONTAINS(description.text, r\"(IC50|IC[\\s_\\-]*50|IC₅₀|ic50|ic[\\s_\\-]*50|Ki|ki|K[iI]|k[iI]|Kd|kd|K[dD]|k[dD]|EC50|EC[\\s_\\-]*50|EC₅₀|ec50|ec[\\s_\\-]*50|pIC50|pIC[\\s_\\-]*50|pIC₅₀|pic50|pic[\\s_\\-]*50|pEC50|pEC[\\s_\\-]*50|pEC₅₀|pec50|pec[\\s_\\-]*50|pKi|pki|pK[iI]|pk[iI]|pKd|pkd|pK[dD]|pk[dD]|logIC50|log[\\s]*IC50|log[\\s]*\\([\\s]*IC50[\\s]*\\)|-log[\\s]*\\([\\s]*IC50[\\s]*\\)|logKi|log[\\s]*Ki|log[\\s]*\\([\\s]*Ki[\\s]*\\)|-log[\\s]*\\([\\s]*Ki[\\s]*\\)|logKd|log[\\s]*Kd|log[\\s]*\\([\\s]*Kd[\\s]*\\)|-log[\\s]*\\([\\s]*Kd[\\s]*\\)|logEC50|log[\\s]*EC50|log[\\s]*\\([\\s]*EC50[\\s]*\\)|-log[\\s]*\\([\\s]*EC50[\\s]*\\)|inhibition[\\s\\-]*constant|dissociation[\\s\\-]*constant|binding[\\s\\-]*constant|half[\\s\\-]*maximal[\\s\\-]*inhibitory[\\s\\-]*concentration|half[\\s\\-]*maximal[\\s\\-]*effective[\\s\\-]*concentration|binding[\\s\\-]*assay)\")\n",
    "    AND\n",
    "    EXISTS(\n",
    "        SELECT 1\n",
    "        FROM UNNEST(t1.ipc) AS ipc_code_record\n",
    "        WHERE ipc_code_record.code LIKE 'A61K%' OR ipc_code_record.code LIKE 'A61P%'\n",
    "    )\n",
    "    ORDER BY 1\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Write result to a temp table for chunked download\n",
    "temp_table_id = f\"{PROJECT_ID}.temp.temp_table_{uuid.uuid4().hex[:8]}\"\n",
    "client.create_dataset(\"temp\", exists_ok=True)\n",
    "job_config = bigquery.QueryJobConfig(destination=temp_table_id, write_disposition=\"WRITE_TRUNCATE\")\n",
    "query_job = client.query(QUERY, job_config=job_config)\n",
    "query_job.result()\n",
    "print(f\"Results written to {temp_table_id}\")\n",
    "\n",
    "# Step 1.5: Optionally create target table with Unicode support\n",
    "from sqlalchemy import text\n",
    "engine = create_engine(\n",
    "    \"postgresql+psycopg2://vshepard@localhost:54368/postgres\"\n",
    ")\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS patents_filtered (\n",
    "            publication_number TEXT,\n",
    "            description_text   TEXT,\n",
    "            publication_date   DATE\n",
    "        );\n",
    "    \"\"\"))\n",
    "\n",
    "# Step 2: Download and upload in chunks\n",
    "CHUNK_SIZE = 1000\n",
    "offset = 0\n",
    "table_name = \"patents_filtered\"\n",
    "total_rows = 0\n",
    "\n",
    "while True:\n",
    "    chunk_query = f\"SELECT * FROM `{temp_table_id}` LIMIT {CHUNK_SIZE} OFFSET {offset}\"\n",
    "    df = client.query(chunk_query).to_dataframe()\n",
    "    if df.empty:\n",
    "        break\n",
    "\n",
    "    # Optional: re-encode text columns to ensure utf-8, not strictly needed with PostgreSQL TEXT\n",
    "    # df['description_text'] = df['description_text'].astype(str).map(lambda x: x.encode('utf-8', 'replace').decode('utf-8'))\n",
    "\n",
    "    # Write chunk to PostgreSQL\n",
    "    df.to_sql(table_name, engine, if_exists='append', index=False, method='multi', chunksize=1000)\n",
    "    total_rows += len(df)\n",
    "    print(f\"Wrote rows {offset} to {offset+len(df)}\")\n",
    "\n",
    "    if len(df) < CHUNK_SIZE:\n",
    "        break\n",
    "    offset += CHUNK_SIZE\n",
    "\n",
    "print(f\"✅ All done. Total rows written: {total_rows}\")\n",
    "\n",
    "# Step 3: Delete temp table\n",
    "client.delete_table(temp_table_id, not_found_ok=True)\n",
    "print(f\"Deleted temp table {temp_table_id}\")\n",
    "\n",
    "# Step 4: (Optional) Save to CSV/Parquet with Unicode support\n",
    "# df.to_csv(\"patents_filtered.csv\", index=False, encoding=\"utf-8\")\n",
    "# df.to_parquet(\"patents_filtered.parquet\", index=False)\n"
   ],
   "id": "de364180c0feeb0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to patent-reciever.temp.temp_table_c1289f69\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character '\\u03b2' in position 4287: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnicodeEncodeError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 53\u001B[0m\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;66;03m# Write chunk to PostgreSQL, create table if first chunk\u001B[39;00m\n\u001B[0;32m---> 53\u001B[0m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtable_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mif_exists\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mappend\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmulti\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m total_rows \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(df)\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWrote rows \u001B[39m\u001B[38;5;132;01m{\u001B[39;00moffset\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00moffset\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mlen\u001B[39m(df)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    327\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    328\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    329\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[1;32m    330\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    331\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    332\u001B[0m     )\n\u001B[0;32m--> 333\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:3106\u001B[0m, in \u001B[0;36mNDFrame.to_sql\u001B[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001B[0m\n\u001B[1;32m   2908\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2909\u001B[0m \u001B[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001B[39;00m\n\u001B[1;32m   2910\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3102\u001B[0m \u001B[38;5;124;03m[(1,), (None,), (2,)]\u001B[39;00m\n\u001B[1;32m   3103\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m  \u001B[38;5;66;03m# noqa: E501\u001B[39;00m\n\u001B[1;32m   3104\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mio\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sql\n\u001B[0;32m-> 3106\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msql\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_sql\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3107\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3108\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3109\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3110\u001B[0m \u001B[43m    \u001B[49m\u001B[43mschema\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3111\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_exists\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_exists\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3112\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3113\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3114\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3115\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3116\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3117\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/io/sql.py:844\u001B[0m, in \u001B[0;36mto_sql\u001B[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001B[0m\n\u001B[1;32m    839\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[1;32m    840\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mframe\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m argument should be either a Series or a DataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    841\u001B[0m     )\n\u001B[1;32m    843\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m pandasSQL_builder(con, schema\u001B[38;5;241m=\u001B[39mschema, need_transaction\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m pandas_sql:\n\u001B[0;32m--> 844\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpandas_sql\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_sql\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    845\u001B[0m \u001B[43m        \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    846\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    847\u001B[0m \u001B[43m        \u001B[49m\u001B[43mif_exists\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_exists\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    848\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    849\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    850\u001B[0m \u001B[43m        \u001B[49m\u001B[43mschema\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    851\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    853\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    854\u001B[0m \u001B[43m        \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mengine_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    856\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/io/sql.py:2030\u001B[0m, in \u001B[0;36mSQLDatabase.to_sql\u001B[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001B[0m\n\u001B[1;32m   2018\u001B[0m sql_engine \u001B[38;5;241m=\u001B[39m get_engine(engine)\n\u001B[1;32m   2020\u001B[0m table \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_table(\n\u001B[1;32m   2021\u001B[0m     frame\u001B[38;5;241m=\u001B[39mframe,\n\u001B[1;32m   2022\u001B[0m     name\u001B[38;5;241m=\u001B[39mname,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2027\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[1;32m   2028\u001B[0m )\n\u001B[0;32m-> 2030\u001B[0m total_inserted \u001B[38;5;241m=\u001B[39m \u001B[43msql_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minsert_records\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2031\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2032\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2033\u001B[0m \u001B[43m    \u001B[49m\u001B[43mframe\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2034\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2035\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2036\u001B[0m \u001B[43m    \u001B[49m\u001B[43mschema\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2037\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2038\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2039\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mengine_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2040\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2042\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_case_sensitive(name\u001B[38;5;241m=\u001B[39mname, schema\u001B[38;5;241m=\u001B[39mschema)\n\u001B[1;32m   2043\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m total_inserted\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/io/sql.py:1570\u001B[0m, in \u001B[0;36mSQLAlchemyEngine.insert_records\u001B[0;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001B[0m\n\u001B[1;32m   1567\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msqlalchemy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m exc\n\u001B[1;32m   1569\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1570\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minsert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1571\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m exc\u001B[38;5;241m.\u001B[39mStatementError \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m   1572\u001B[0m     \u001B[38;5;66;03m# GH34431\u001B[39;00m\n\u001B[1;32m   1573\u001B[0m     \u001B[38;5;66;03m# https://stackoverflow.com/a/67358288/6067848\u001B[39;00m\n\u001B[1;32m   1574\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m(1054, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown column \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minf(e0)?\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m in \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfield list\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m))(?#\u001B[39m\n\u001B[1;32m   1575\u001B[0m \u001B[38;5;124m    )|inf can not be used with MySQL\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/io/sql.py:1121\u001B[0m, in \u001B[0;36mSQLTable.insert\u001B[0;34m(self, chunksize, method)\u001B[0m\n\u001B[1;32m   1118\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m   1120\u001B[0m chunk_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39m(arr[start_i:end_i] \u001B[38;5;28;01mfor\u001B[39;00m arr \u001B[38;5;129;01min\u001B[39;00m data_list))\n\u001B[0;32m-> 1121\u001B[0m num_inserted \u001B[38;5;241m=\u001B[39m \u001B[43mexec_insert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1122\u001B[0m \u001B[38;5;66;03m# GH 46891\u001B[39;00m\n\u001B[1;32m   1123\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_inserted \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/io/sql.py:1029\u001B[0m, in \u001B[0;36mSQLTable._execute_insert_multi\u001B[0;34m(self, conn, keys, data_iter)\u001B[0m\n\u001B[1;32m   1027\u001B[0m data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mdict\u001B[39m(\u001B[38;5;28mzip\u001B[39m(keys, row)) \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m data_iter]\n\u001B[1;32m   1028\u001B[0m stmt \u001B[38;5;241m=\u001B[39m insert(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtable)\u001B[38;5;241m.\u001B[39mvalues(data)\n\u001B[0;32m-> 1029\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstmt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1030\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\u001B[38;5;241m.\u001B[39mrowcount\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1415\u001B[0m, in \u001B[0;36mConnection.execute\u001B[0;34m(self, statement, parameters, execution_options)\u001B[0m\n\u001B[1;32m   1413\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc\u001B[38;5;241m.\u001B[39mObjectNotExecutableError(statement) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   1414\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1415\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmeth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1416\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1417\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdistilled_parameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1418\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexecution_options\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mNO_OPTIONS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1419\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:523\u001B[0m, in \u001B[0;36mClauseElement._execute_on_connection\u001B[0;34m(self, connection, distilled_params, execution_options)\u001B[0m\n\u001B[1;32m    521\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m TYPE_CHECKING:\n\u001B[1;32m    522\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, Executable)\n\u001B[0;32m--> 523\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_clauseelement\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdistilled_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexecution_options\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    527\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc\u001B[38;5;241m.\u001B[39mObjectNotExecutableError(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637\u001B[0m, in \u001B[0;36mConnection._execute_clauseelement\u001B[0;34m(self, elem, distilled_parameters, execution_options)\u001B[0m\n\u001B[1;32m   1625\u001B[0m compiled_cache: Optional[CompiledCacheType] \u001B[38;5;241m=\u001B[39m execution_options\u001B[38;5;241m.\u001B[39mget(\n\u001B[1;32m   1626\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompiled_cache\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine\u001B[38;5;241m.\u001B[39m_compiled_cache\n\u001B[1;32m   1627\u001B[0m )\n\u001B[1;32m   1629\u001B[0m compiled_sql, extracted_params, cache_hit \u001B[38;5;241m=\u001B[39m elem\u001B[38;5;241m.\u001B[39m_compile_w_cache(\n\u001B[1;32m   1630\u001B[0m     dialect\u001B[38;5;241m=\u001B[39mdialect,\n\u001B[1;32m   1631\u001B[0m     compiled_cache\u001B[38;5;241m=\u001B[39mcompiled_cache,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1635\u001B[0m     linting\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdialect\u001B[38;5;241m.\u001B[39mcompiler_linting \u001B[38;5;241m|\u001B[39m compiler\u001B[38;5;241m.\u001B[39mWARN_LINTING,\n\u001B[1;32m   1636\u001B[0m )\n\u001B[0;32m-> 1637\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_context\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1638\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdialect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1639\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdialect\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecution_ctx_cls\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init_compiled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1640\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompiled_sql\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1641\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdistilled_parameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1642\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexecution_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1643\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompiled_sql\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1644\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdistilled_parameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1645\u001B[0m \u001B[43m    \u001B[49m\u001B[43melem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1646\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextracted_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1647\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_hit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_hit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1648\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1649\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_events:\n\u001B[1;32m   1650\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch\u001B[38;5;241m.\u001B[39mafter_execute(\n\u001B[1;32m   1651\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1652\u001B[0m         elem,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1656\u001B[0m         ret,\n\u001B[1;32m   1657\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1842\u001B[0m, in \u001B[0;36mConnection._execute_context\u001B[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001B[0m\n\u001B[1;32m   1840\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exec_insertmany_context(dialect, context)\n\u001B[1;32m   1841\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1842\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_exec_single_context\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1843\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdialect\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\n\u001B[1;32m   1844\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982\u001B[0m, in \u001B[0;36mConnection._exec_single_context\u001B[0;34m(self, dialect, context, statement, parameters)\u001B[0m\n\u001B[1;32m   1979\u001B[0m     result \u001B[38;5;241m=\u001B[39m context\u001B[38;5;241m.\u001B[39m_setup_result_proxy()\n\u001B[1;32m   1981\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m-> 1982\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_dbapi_exception\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1983\u001B[0m \u001B[43m        \u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstr_statement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meffective_parameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcursor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\n\u001B[1;32m   1984\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1986\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2354\u001B[0m, in \u001B[0;36mConnection._handle_dbapi_exception\u001B[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001B[0m\n\u001B[1;32m   2352\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2353\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m exc_info[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 2354\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m exc_info[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mwith_traceback(exc_info[\u001B[38;5;241m2\u001B[39m])\n\u001B[1;32m   2355\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   2356\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reentrant_error\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963\u001B[0m, in \u001B[0;36mConnection._exec_single_context\u001B[0;34m(self, dialect, context, statement, parameters)\u001B[0m\n\u001B[1;32m   1961\u001B[0m                 \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m   1962\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m evt_handled:\n\u001B[0;32m-> 1963\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdialect\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_execute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1964\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcursor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstr_statement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meffective_parameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\n\u001B[1;32m   1965\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1967\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_events \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine\u001B[38;5;241m.\u001B[39m_has_events:\n\u001B[1;32m   1968\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch\u001B[38;5;241m.\u001B[39mafter_cursor_execute(\n\u001B[1;32m   1969\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1970\u001B[0m         cursor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1974\u001B[0m         context\u001B[38;5;241m.\u001B[39mexecutemany,\n\u001B[1;32m   1975\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py:943\u001B[0m, in \u001B[0;36mDefaultDialect.do_execute\u001B[0;34m(self, cursor, statement, parameters, context)\u001B[0m\n\u001B[1;32m    942\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdo_execute\u001B[39m(\u001B[38;5;28mself\u001B[39m, cursor, statement, parameters, context\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 943\u001B[0m     \u001B[43mcursor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mUnicodeEncodeError\u001B[0m: 'ascii' codec can't encode character '\\u03b2' in position 4287: ordinal not in range(128)"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-28T23:32:05.017908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "client = bigquery.Client()\n",
    "PROJECT_ID = \"patent-reciever\"\n",
    "QUERY = \"\"\"\n",
    "SELECT\n",
    "    t1.publication_number,\n",
    "    description.text AS description_text,\n",
    "    t1.publication_date\n",
    "FROM\n",
    "    `bigquery-public-data.patents.publications` AS t1,\n",
    "    UNNEST(t1.description_localized) AS description\n",
    "WHERE\n",
    "    REGEXP_CONTAINS(description.text, r\"(IC50|IC[\\s_\\-]*50|IC₅₀|ic50|ic[\\s_\\-]*50|Ki|ki|K[iI]|k[iI]|Kd|kd|K[dD]|k[dD]|EC50|EC[\\s_\\-]*50|EC₅₀|ec50|ec[\\s_\\-]*50|pIC50|pIC[\\s_\\-]*50|pIC₅₀|pic50|pic[\\s_\\-]*50|pEC50|pEC[\\s_\\-]*50|pEC₅₀|pec50|pec[\\s_\\-]*50|pKi|pki|pK[iI]|pk[iI]|pKd|pkd|pK[dD]|pk[dD]|logIC50|log[\\s]*IC50|log[\\s]*\\([\\s]*IC50[\\s]*\\)|-log[\\s]*\\([\\s]*IC50[\\s]*\\)|logKi|log[\\s]*Ki|log[\\s]*\\([\\s]*Ki[\\s]*\\)|-log[\\s]*\\([\\s]*Ki[\\s]*\\)|logKd|log[\\s]*Kd|log[\\s]*\\([\\s]*Kd[\\s]*\\)|-log[\\s]*\\([\\s]*Kd[\\s]*\\)|logEC50|log[\\s]*EC50|log[\\s]*\\([\\s]*EC50[\\s]*\\)|-log[\\s]*\\([\\s]*EC50[\\s]*\\)|inhibition[\\s\\-]*constant|dissociation[\\s\\-]*constant|binding[\\s\\-]*constant|half[\\s\\-]*maximal[\\s\\-]*inhibitory[\\s\\-]*concentration|half[\\s\\-]*maximal[\\s\\-]*effective[\\s\\-]*concentration|binding[\\s\\-]*assay)\")\n",
    "    AND\n",
    "    EXISTS(\n",
    "        SELECT 1\n",
    "        FROM UNNEST(t1.ipc) AS ipc_code_record\n",
    "        WHERE ipc_code_record.code LIKE 'A61K%' OR ipc_code_record.code LIKE 'A61P%'\n",
    "    )\n",
    "    ORDER BY 1\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Write result to a temp table for chunked download\n",
    "temp_table_id = f\"{PROJECT_ID}.temp.temp_table_{uuid.uuid4().hex[:8]}\"\n",
    "client.create_dataset(\"temp\", exists_ok=True)\n",
    "job_config = bigquery.QueryJobConfig(destination=temp_table_id, write_disposition=\"WRITE_TRUNCATE\")\n",
    "query_job = client.query(QUERY, job_config=job_config)\n",
    "query_job.result()\n",
    "print(f\"Results written to {temp_table_id}\")\n",
    "\n",
    "# Step 2: Download and save in Parquet chunks\n",
    "CHUNK_SIZE = 1000\n",
    "offset = 0\n",
    "total_rows = 0\n",
    "\n",
    "os.makedirs(\"parquet_chunks\", exist_ok=True)  # Create output directory if it doesn't exist\n",
    "chunk_idx = 0\n",
    "\n",
    "while True:\n",
    "    chunk_query = f\"SELECT * FROM `{temp_table_id}` LIMIT {CHUNK_SIZE} OFFSET {offset}\"\n",
    "    df = client.query(chunk_query).to_dataframe()\n",
    "    if df.empty:\n",
    "        break\n",
    "\n",
    "    # Save chunk as a Parquet file\n",
    "    parquet_path = f\"parquet_chunks/patents_chunk_{chunk_idx:05d}.parquet\"\n",
    "    df.to_parquet(parquet_path, index=False)\n",
    "    print(f\"Saved {len(df)} rows to {parquet_path}\")\n",
    "\n",
    "    total_rows += len(df)\n",
    "    if len(df) < CHUNK_SIZE:\n",
    "        break\n",
    "    offset += CHUNK_SIZE\n",
    "    chunk_idx += 1\n",
    "\n",
    "print(f\"✅ All done. Total rows saved: {total_rows}\")\n",
    "\n",
    "# Step 3: Delete temp table\n",
    "client.delete_table(temp_table_id, not_found_ok=True)\n",
    "print(f\"Deleted temp table {temp_table_id}\")\n"
   ],
   "id": "aa0365aa7b172935",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to patent-reciever.temp.temp_table_1e767178\n",
      "Saved 1000 rows to parquet_chunks/patents_chunk_00000.parquet\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
