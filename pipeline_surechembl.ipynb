{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Получаем данные из Surechembl db",
   "id": "2ba23bc423eb0614"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-07-18T12:14:56.166239765Z",
     "start_time": "2025-07-18T11:32:17.372385Z"
    }
   },
   "source": [
    "import duckdb, pyarrow.parquet as pq\n",
    "\n",
    "OUT_PARQUET = \"./output/pharma_patents_2020.parquet\"\n",
    "DUCKDB_FILE = \"/home/vshepard/hackaton_life/surecheml_db.duckdb\"\n",
    "\n",
    "q = f\"\"\"\n",
    "COPY (\n",
    "    WITH pharma_cpc AS (\n",
    "        SELECT DISTINCT id\n",
    "        FROM patents, UNNEST(cpc) t(code)\n",
    "        WHERE trim(code) LIKE 'A61K%' OR trim(code) LIKE 'A61P%'\n",
    "    ), pharma_ipc AS (\n",
    "        SELECT DISTINCT id\n",
    "        FROM patents, UNNEST(ipc) t(code)\n",
    "        WHERE trim(code) LIKE 'A61K%' OR trim(code) LIKE 'A61P%'\n",
    "    ), pharma_ids AS (\n",
    "        SELECT id FROM pharma_cpc\n",
    "        UNION\n",
    "        SELECT id FROM pharma_ipc\n",
    "    )\n",
    "    SELECT DISTINCT\n",
    "           p.patent_number,\n",
    "           c.id          AS compound_id,\n",
    "           c.smiles,\n",
    "           c.inchi_key\n",
    "    FROM   pharma_ids  pid\n",
    "    JOIN   patents     p   ON p.id = pid.id and p.publication_date >= '2020-01-01'\n",
    "    JOIN   patent_compound_map pcm ON pcm.patent_id = p.id\n",
    "    JOIN   compounds   c   ON c.id = pcm.compound_id AND c.smiles <> 'N' and c.smiles IS NOT NULL\n",
    "    JOIN   fields      f   ON f.id = pcm.field_id and f.fieldname = 'desc'\n",
    ")\n",
    "TO '{OUT_PARQUET}'\n",
    "WITH (FORMAT PARQUET, COMPRESSION 'ZSTD');\n",
    "\"\"\"\n",
    "\n",
    "duckdb.connect(DUCKDB_FILE).execute(q)\n",
    "print(\"Parquet written →\", OUT_PARQUET, \"| rows =\", pq.ParquetFile(OUT_PARQUET).metadata.num_rows)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T12:18:55.172612Z",
     "start_time": "2025-07-18T12:18:55.073287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check step 1\n",
    "import duckdb\n",
    "\n",
    "file = \"./output/pharma_patents_2020.parquet\"\n",
    "\n",
    "query = f\"\"\"\n",
    "    SELECT count(1)\n",
    "    FROM '{file}';\n",
    "    \"\"\"\n",
    "res = duckdb.query(query).fetchall()\n",
    "print(res)"
   ],
   "id": "ded097695bf58fc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(131538147,)]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Отфильтровать статьи с данными измерений IC50|Ki|EC50|Kd",
   "id": "89230cef4522ceb8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T15:21:18.307267Z",
     "start_time": "2025-07-18T15:21:12.466837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import duckdb\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "file = \"./output/pharma_patents_2020.parquet\"\n",
    "output_csv = \"./output/patents_with_ic50_ki_ec50.csv\"\n",
    "\n",
    "# 1. Get all unique patent numbers (already deduplicated)\n",
    "query = f\"SELECT patent_number, list(smiles) AS smiles_array FROM '{file}' group by 1 limit 10;\"\n",
    "patent_rows = duckdb.query(query).fetchall()\n",
    "\n",
    "def process_patent(patent_number):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless=new\")\n",
    "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=chrome_options)\n",
    "    url = f\"https://www.surechembl.org/patent/{patent_number}\"\n",
    "    found = None\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(6)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        description_section = None\n",
    "        # Extract description\n",
    "        for el in soup.find_all(class_=lambda c: c and 'description' in c):\n",
    "            sec = el.find(class_='section')\n",
    "            if sec:\n",
    "                description_section = sec.get_text(separator=\" \", strip=True)\n",
    "                break\n",
    "\n",
    "        # Check for bioactivity keywords: ('Ki (nM)', 'IC50 (nM)', 'Kd (nM)', 'EC50 (nM)')\n",
    "        if description_section and re.search(r'\\b(IC50|Ki|EC50|Kd|pIC50|pKi|pKd)\\b', description_section, re.IGNORECASE):\n",
    "            found = description_section\n",
    "    except Exception as e:\n",
    "        print(f\"Error with patent {patent_number}: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return found"
   ],
   "id": "37712fded919bc09",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are ChemExtract‑GPT, a meticulous chemoinformatics extractor.\n",
    "Output ONLY CSV lines and NOTHING else.\n",
    "Columns (in order):\n",
    "latent_number,Ligand,SMILES,InChIKey,Protein Name,UniProt,Affinity Type,Affinity (nM),Temp (°C),pH,Assay Notes\n",
    "Rules:\n",
    "1. Each line must correspond to one quantitative binding measurement (Ki, IC50, Kd, EC50).\n",
    "2. Convert any pX values to nanomolar:  IC50(M) = 10^(−pIC50); multiply by 1e9 to get nM.\n",
    "3. Convert μM, mM, pM → nM.\n",
    "4. “Protein Name” must be the explicit target name appearing in the text; map to the best UniProt accession if possible (else leave empty).\n",
    "5. Do **not** emit commentary, explanations, Markdown, or extra whitespace — only the CSV header once and data lines. If there is no required binding measurement (Ki, IC50, Kd, EC50) write nothing.\n",
    "\"\"\""
   ],
   "id": "6d635af4388a58f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Поиск значений измерений",
   "id": "6b26607432ecc927"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T15:36:53.795240Z",
     "start_time": "2025-07-18T15:26:46.452115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv, json, logging, shelve, time, requests\n",
    "from typing import List, Dict\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# CONSTANTS\n",
    "# ------------------------------------------------------------------------------\n",
    "CACHE_PATH   = \"./output/patent_html_cache.db\"\n",
    "OUT_CSV      = \"./output/bindingdb_upload.csv\"\n",
    "LLM_MODEL    = \"llama-3.3-70b-instruct\"\n",
    "OPENAI_API_KEY  = \"dummy-key\"\n",
    "OPENAI_BASE_URL = \"http://80.209.242.40:8000/v1\"\n",
    "TEMPERATURE  = 0.25\n",
    "MAX_TOKENS   = 2048\n",
    "CSV_HEADER = [\"Patent\",\"LigandID\",\"SMILES\",\"InChIKey\",\"Protein Name\",\"UniProt\",\n",
    "              \"Affinity Type\",\"Affinity (nM)\",\"Temp (°C)\",\"pH\",\"Assay Notes\"]\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are BioFilter-GPT, an expert in patent text mining for biochemical data extraction.\n",
    "\n",
    "Your job is to **extract only those portions of the text** that are likely to contain information needed to fill the following CSV fields:\n",
    "\n",
    "Patent, LigandID, SMILES, InChIKey, Protein Name, UniProt, Affinity Type, Affinity (nM), Temp (°C), pH, Assay Notes\n",
    "\n",
    "**Relevance rules:**\n",
    "- Keep any sentence, paragraph, or table mentioning binding affinity values (e.g., Ki, IC50, EC50, Kd).\n",
    "- Keep text that mentions experimental conditions, such as temperature, pH, buffers, solvents, or assay method.\n",
    "- Keep text describing target proteins or their identifiers (gene name, Uniprot accession, etc.).\n",
    "- Keep text describing the compound, such as SMILES, InChI, or structure-related data.\n",
    "- Discard introductions, unrelated background, legal boilerplate, patent claims that do not reference measurements or proteins, etc.\n",
    "\n",
    "**Output only the minimal necessary text fragments** (preferably in their original order) that could be useful for structured extraction.\n",
    "Do not summarize, paraphrase, or add any commentary.\n",
    "\n",
    "If no relevant content is found, return an empty string.\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "USER_TEMPLATE = \"\"\"\n",
    "Below is the full text of a chemical patent.\n",
    "**Extract and return only the sentences, paragraphs, or tables** likely to contain:\n",
    "- Quantitative binding measurements (Ki, IC50, Kd, EC50)\n",
    "- Descriptions of the experiment (temperature, pH, buffer, detection method, cell line, etc.)\n",
    "- Protein targets or gene identifiers\n",
    "- Compound identifiers (SMILES, InChI, InChIKey)\n",
    "\n",
    "Do NOT include irrelevant patent sections, background, or legal text.\n",
    "----- BEGIN PATENT TEXT -----\n",
    "{FULL_PATENT_TEXT}\n",
    "----- END PATENT TEXT -----\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT2 = \"\"\"\n",
    "You are ChemExtract-GPT, a meticulous chemoinformatics extractor.\n",
    "\n",
    "Your task is to extract structured biochemical binding data from chemical patent text and output it as CSV lines with these columns, in order:\n",
    "\n",
    "Patent,LigandID,SMILES,InChIKey,Protein Name,UniProt,Affinity Type,Affinity (nM),Temp (°C),pH,Assay Notes\n",
    "\n",
    "**Instructions:**\n",
    "- Each line must correspond to one quantitative binding measurement (Ki, IC50, Kd, EC50, pKi, pIC50, pKd, pEC50).\n",
    "- For pIC50, pKi, or pKd, convert to nM using: IC50(M) = 10^(−pIC50); multiply by 1e9 to get nM.\n",
    "- Convert all values to nM (μM × 1e3, mM × 1e6, pM × 1e-3).\n",
    "- “Protein Name” must be the explicit target name.\n",
    "- Fill \"Assay Notes\" with up to 255 characters describing buffer, detection method, or cell line if available.\n",
    "- Omit duplicate (Patent, LigandID, Protein, Affinity Type, Affinity) pairs.\n",
    "- Output **ONLY** the CSV header (once) and data lines—no extra commentary, Markdown, or whitespace.\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "USER_TEMPLATE2 = \"\"\"\n",
    "Below is a cleaned excerpt from a chemical patent, plus relevant identifiers.\n",
    "\n",
    "Patent number: {PATENT_NUMBER}\n",
    "SMILES: {SMILES}\n",
    "\n",
    "----- BEGIN RELEVANT PATENT TEXT -----\n",
    "{FULL_PATENT_TEXT}\n",
    "----- END RELEVANT PATENT TEXT -----\n",
    "\n",
    "**Extract and output all relevant binding measurements and assay details in the requested CSV format.**\n",
    "\"\"\"\n",
    "# ------------------------------------------------------------------------------\n",
    "# SESSION (all headers in one place)\n",
    "# ------------------------------------------------------------------------------\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    \"User-Agent\":  \"ChemExtract/0.1 (+https://github.com/you)\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer {}\".format(OPENAI_API_KEY)\n",
    "})\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# HELPER FUNCTIONS\n",
    "# ------------------------------------------------------------------------------\n",
    "def build_messages(row: pd.Series, text: str, user_temp, system_prompt) -> List[Dict[str, str]]:\n",
    "    user_msg = user_temp.format(\n",
    "        PATENT_NUMBER=row[0],\n",
    "        SMILES=row[1],\n",
    "        FULL_PATENT_TEXT=text\n",
    "    )\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\",   \"content\": user_msg}\n",
    "    ]\n",
    "\n",
    "\n",
    "def call_llama(messages: List[Dict[str, str]]) -> str:\n",
    "    payload = {\n",
    "        \"model\": LLM_MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": MAX_TOKENS,\n",
    "        \"temperature\": TEMPERATURE\n",
    "    }\n",
    "    resp = session.post(\"{}/chat/completions\".format(OPENAI_BASE_URL),\n",
    "                        json=payload, timeout=90)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "def parse_csv_response(csv_text: str) -> List[List[str]]:\n",
    "    lines = [l.strip() for l in csv_text.strip().splitlines() if l.strip()]\n",
    "    if lines and lines[0].lower().startswith(\"patent,\"):\n",
    "        lines = lines[1:]\n",
    "    return [next(csv.reader([line])) for line in lines]\n",
    "\n",
    "\n",
    "def split_text_for_llm(text: str, max_length: int = 4000) -> List[str]:\n",
    "    \"\"\"Greedy paragraph splitter that respects max_length.\"\"\"\n",
    "    if len(text) <= max_length:\n",
    "        return [text]\n",
    "\n",
    "    paras, chunks, current = text.split(\"\\n\\n\"), [], \"\"\n",
    "    for p in paras:\n",
    "        if len(current) + len(p) + 2 <= max_length:\n",
    "            current += p + \"\\n\\n\"\n",
    "        else:\n",
    "            if current:\n",
    "                chunks.append(current.rstrip())\n",
    "            current = p + \"\\n\\n\"\n",
    "    if current:\n",
    "        chunks.append(current.rstrip())\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# MAIN DRIVER\n",
    "# ------------------------------------------------------------------------------\n",
    "def process_llm():\n",
    "    logging.info(\"Processing {} patents\".format(len(patent_rows)))\n",
    "\n",
    "    with open(OUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as out_fh:\n",
    "        writer = csv.writer(out_fh)\n",
    "        writer.writerow(CSV_HEADER)\n",
    "\n",
    "        for row in patent_rows:\n",
    "            # 1) get full text (cached)\n",
    "            full_text = process_patent(row[0])\n",
    "            if not full_text:\n",
    "                continue\n",
    "            # 2) chunk if necessary\n",
    "            text = \"\"\n",
    "            for chunk in split_text_for_llm(full_text, max_length=4000):\n",
    "                messages1 = build_messages(row, chunk, USER_TEMPLATE, SYSTEM_PROMPT)\n",
    "                text += call_llama(messages1)\n",
    "\n",
    "            messages2 = build_messages(row, text, USER_TEMPLATE2, SYSTEM_PROMPT2)\n",
    "            llm_raw = call_llama(messages2)\n",
    "\n",
    "            # 3) parse and write\n",
    "            for csv_row in parse_csv_response(llm_raw):\n",
    "                writer.writerow(csv_row)\n",
    "\n",
    "\n",
    "process_llm()\n"
   ],
   "id": "76004dd196c31990",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with patent US-10954289-B1: HTTPConnectionPool(host='localhost', port=40565): Read timed out. (read timeout=120)\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
